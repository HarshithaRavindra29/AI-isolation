
# Isolation - Game Playing Agent

## Overview

Isolation is a deterministic, two-player game of perfect information in which the players alternate turns moving a single piece from one cell to another on a board.  Whenever either player occupies a cell, that cell becomes blocked for the remainder of the game.  The first player with no remaining legal moves loses, and the opponent is declared the winner.

This project is an attempt at building a game playing 'adversarial search' agent for Isolation combining different strategies. Concepts covered in this project include:
- Building a game tree
- Minimax search
- Alphabeta search (optimization of minimax)
- Iterative deepening
- Quiessance search
- Evaluation functions

This project uses a version of Isolation where each agent is restricted to L-shaped movements (like a knight in chess) on a rectangular grid (like a chess or checkerboard).  The agents can move to any open cell on the board that is 2-rows and 1-column or 2-columns and 1-row away from their current position on the board. Movements are blocked at the edges of the board (the board does not wrap around), however, the player can "jump" blocked or occupied spaces (just like a knight in chess).

Additionally, agents have a fixed time limit each turn to search for the best move and respond. If the time limit expires during a player's turn, that player forfeits the match, and the opponent wins.

## Design

The project is divided into _ sections.

### Isolation Board

This component manages the state of the board game, which includes the location of players on the board, the positions that have already been played, the positions that each player can play, and the winning losing players at end game. It has no logic built into it except the ability to determine the set of possible moves for the active player on each turn. The choice of the move however is delegated to the players, which is where the 'intelligence' lies.

### Visualizer

This component provides a visualization of the Isolation board, given the sequence of moves that were generated by the players. It is at present only an after-the-fact visualiation, so the entire history of moves for the game (start to finish) must be known before invoking the visualizer. At a later point, it is my hope to change that so that the visualizer is more interactive, providing the opportunity for even a human player to get involved in playing the game.

### Game Playing Agents

These are the components, as mentioned above, wherein the game playing intelligence lies. Different game playing agents can exist, each implementing a different game playing strategy/algorithm.

The entry point into the game playing intelligence is through the 'get_moves()' method:

```
    def get_move(self, game, legal_moves, time_left):
        """Searches for the best move from the available legal moves and returns a
        result before the time limit expires.

        This function must perform iterative deepening if self.iterative=True,
        and it must use the search method (minimax or alphabeta) corresponding
        to the self.method value.

        **********************************************************************
        NOTE: If time_left < 0 when this function returns, the agent will
              forfeit the game due to timeout. The agent must return _before_ the
              timer reaches 0.
        **********************************************************************

        Parameters
        ----------
        game : `isolation.Board`
            An instance of `isolation.Board` encoding the current state of the
            game (e.g., player locations and blocked cells).

        legal_moves : list<(int, int)>
            A list containing legal moves. Moves are encoded as tuples of pairs
            of ints defining the next (row, col) for the agent to occupy.

        time_left : callable
            A function that returns the number of milliseconds left in the
            current turn. Returning with any less than 0 ms remaining forfeits
            the game.

        Returns
        -------
        (int, int)
            Board coordinates corresponding to a legal move; may return
            (-1, -1) if there are no available legal moves.
        """
```

#### Adversarial Search Agent

This game playing agent uses adversarial search to determine the next best move to return when its get_move() api is invoked. Various aspects of adversarial search are discussed below.

##### Game Tree Traversal

Adversarial search involves building a game tree for the current state of the board, given the available next moves, and evaluating each subtree (branch) recursively while 'simulating' the progress of the game for each of the move options provided, until a configurable depth has been reached.

There are two traversal mechanisms that have been implemented.

###### Minimax Traversal

With minimax, at each node, the recursive operation performed is as follows:

```
def minimax(self, game, depth, maximizing_player=True):
    ...
    ...
    ...
    floor = float('-inf')
    ceiling = float('+inf')
    legal_moves = game.get_legal_moves(game.active_player)
    if legal_moves and len(legal_moves)>0:
        if depth>0: # Recursive case:
            if maximizing_player:   # MAXIMIZING ply
                score, move = floor, None
                for i,m in enumerate(legal_moves):
                    newscore, _ = self.minimax(game.forecast_move(m), depth-1, maximizing_player=not maximizing_player)
                    if (move is None and newscore == score) or newscore > score:
                        score, move = newscore, m
            else:                   # MINIMIZING ply
                score, move = ceiling, None
                for i,m in enumerate(legal_moves):
                    newscore, _ = self.minimax(game.forecast_move(m), depth-1, maximizing_player=not maximizing_player)
                    if (move is None and newscore == score) or newscore < score:
                        score, move = newscore, m
        else: # Base case (depth==0)
            score, move = self.score(game, self), None
    else:
        score, move = self.score(game, self), (-1, -1)
    return score, move
```

###### Alphabeta traversal

Alpha-beta traversal is an optimization of minimax wherein branches are only explored if they contribute some useful information to the score determination. Branches that yield no useful information are pruned out, thereby avoiding unnecessary traversal overhead. This pruning is achieved by continuously updating an acceptable range for the game tree. Any branches that will yield a score that is outside this range are discarded. The algorithm proceeds just like minimax, with the following added logic:

```
def alphabeta(self, game, depth, alpha=float("-inf"), beta=float("inf"), maximizing_player=True, tab='\t'):
    ...
    ...
    ...
    floor = alpha
    ceiling = beta
    legal_moves = game.get_legal_moves(game.active_player)
    if legal_moves and len(legal_moves)>0:
        if depth>0: # Recursive case:
            if maximizing_player:   # MAXIMIZING ply
                score, move = floor, None
                for i,m in enumerate(legal_moves):
                    newscore, _ = self.alphabeta(game.forecast_move(m), depth-1, floor, ceiling, maximizing_player=not maximizing_player)
                    if newscore is not None:
                        if (move is None and newscore == score) or newscore > score:
                            score, floor, move = newscore, newscore, m
                        if score > ceiling: # Prune: Crossed the upper limit at this max layer already
                            break
            else:                   # MINIMIZING ply
                score, move = ceiling, None
                for i,m in enumerate(legal_moves):
                    newscore, _ = self.alphabeta(game.forecast_move(m), depth-1, floor, ceiling, maximizing_player=not maximizing_player)
                    if newscore is not None:
                        if (move is None and newscore == score) or newscore < score:
                            score, ceiling, move = newscore, newscore, m
                        if score < floor: # Prune: Crossed the lower limit at this min layer already
                                break
            else: # Base case (depth==0)
                score, move = self.score(game, self), None
        else:
            score, move = self.score(game, self), (-1, -1)
        return score, move
```

With alpha-beta traversal, we are guaranteed the same outcome as minimax, yet without the overhead of exploring every game tree branch.

##### Iterative Deepening & Quiessance

```
    ...
    results = deque(maxlen=3)
    for depth in range (self.search_depth, 25):
        score, move = self.dosearch(game, depth)
        results.append((score, move))
        if len(results) >=3 and all(x[1] == move for x in results):
            # Achieved quiessance here since last 3 moves recommendations were identical
            break
        if self.time_left() < 2*self.TIMER_THRESHOLD:
            break
```

##### Board Evaluation Functions

###### Custom 1

```
    if game.is_loser(player):
        return float("-inf")

    if game.is_winner(player):
        return float("inf")

    own_moves = len(game.get_legal_moves(player))
    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))
    return float(own_moves - opp_moves)
```

###### Custom 2

```
    if game.is_loser(player):
        return float("-inf")

    if game.is_winner(player):
        return float("inf")
        
    own_moves = game.get_legal_moves(player)
    opp_moves = game.get_legal_moves(game.get_opponent(player))
    if game.active_player == player:
        return float(len(own_moves) - len(opp_moves))
    else: # It' the opponent's turn, so revise the options a bit
        return float(len([x for x in own_moves if x not in opp_moves]) - len(opp_moves))
```

###### Custom 3



### Tournament

The `tournament.py` script is used to evaluate the effectiveness of your custom_score heuristic.  The script measures relative performance of your agent (called "Student") in a round-robin tournament against several other pre-defined agents.  The Student agent uses time-limited Iterative Deepening and the custom_score heuristic you wrote.

The performance of time-limited iterative deepening search is hardware dependent (faster hardware is expected to search deeper than slower hardware in the same amount of time).  The script controls for these effects by also measuring the baseline performance of an agent called "ID_Improved" that uess Iterative Deepening and the improved_score heuristic from `sample_players.py`.  Your goal is to develop a heuristic such that Student outperforms ID_Improved.

The tournament opponents are listed below. (See also: sample heuristics and players defined in sample_players.py)

- Random: An agent that randomly chooses a move each turn.
- MM_Null: CustomPlayer agent using fixed-depth minimax search and the null_score heuristic
- MM_Open: CustomPlayer agent using fixed-depth minimax search and the open_move_score heuristic
- MM_Improved: CustomPlayer agent using fixed-depth minimax search and the improved_score heuristic
- AB_Null: CustomPlayer agent using fixed-depth alpha-beta search and the null_score heuristic
- AB_Open: CustomPlayer agent using fixed-depth alpha-beta search and the open_move_score heuristic
- AB_Improved: CustomPlayer agent using fixed-depth alpha-beta search and the improved_score heuristic

